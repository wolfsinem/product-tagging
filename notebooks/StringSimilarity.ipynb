{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('/Users/wolfsinem/product-tagging/')\n",
    "from extended_df import model_dataframe\n",
    "\n",
    "sys.path.append('/Users/wolfsinem/product-tagging/product_tagging')\n",
    "from tags_generator import tokenize_string\n",
    "\n",
    "#python built in library to calculate the similarity\n",
    "from difflib import SequenceMatcher\n",
    "import difflib\n",
    "\n",
    "import nltk \n",
    "# nltk.download('averaged_perceptron_tagger') # download once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alisha Solid Women's Cycling Shorts</td>\n",
       "      <td>Key Features of Alisha Solid Women's Cycling S...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FabHomeDecor Fabric Double Sofa Bed</td>\n",
       "      <td>FabHomeDecor Fabric Double Sofa Bed (Finish Co...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AW Bellies</td>\n",
       "      <td>Key Features of AW Bellies Sandals Wedges Heel...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alisha Solid Women's Cycling Shorts</td>\n",
       "      <td>Key Features of Alisha Solid Women's Cycling S...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sicons All Purpose Arnica Dog Shampoo</td>\n",
       "      <td>Specifications of Sicons All Purpose Arnica Do...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            product_name  \\\n",
       "0    Alisha Solid Women's Cycling Shorts   \n",
       "1    FabHomeDecor Fabric Double Sofa Bed   \n",
       "2                             AW Bellies   \n",
       "3    Alisha Solid Women's Cycling Shorts   \n",
       "4  Sicons All Purpose Arnica Dog Shampoo   \n",
       "\n",
       "                                         description tags  \n",
       "0  Key Features of Alisha Solid Women's Cycling S...       \n",
       "1  FabHomeDecor Fabric Double Sofa Bed (Finish Co...       \n",
       "2  Key Features of AW Bellies Sandals Wedges Heel...       \n",
       "3  Key Features of Alisha Solid Women's Cycling S...       \n",
       "4  Specifications of Sicons All Purpose Arnica Do...       "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12202, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buy Wallmantra Extra Large Vinyl Stickers Sticker for Rs.2194 online. Wallmantra Extra Large Vinyl Stickers Sticker at best prices with FREE shipping & cash on delivery. Only Genuine Products. 30 Day Replacement Guarantee.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[19967]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buy Wallmantra Extra Large Vinyl Stickers Sticker for Rs.2719 online. Wallmantra Extra Large Vinyl Stickers Sticker at best prices with FREE shipping & cash on delivery. Only Genuine Products. 30 Day Replacement Guarantee.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[19970]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(string1, string2):\n",
    "    \"\"\"Function to calculate the similarity of two (product) descriptions.\n",
    "    \n",
    "    :param string1: This would be the first textual description. \n",
    "    :type string1: string\n",
    "    \n",
    "    :param string2: This would be the second textual description.\n",
    "    :type string2: string\n",
    "    \"\"\"\n",
    "    sequence = SequenceMatcher(None, string1, string2)\n",
    "    score = sequence.ratio()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see, even though I dropped all of the duplicates, product descriptions with a similarity less than 100% stay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9954954954954955"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar(df.loc[19970]['description'],df.loc[19967]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description a and b are exactly the same, thus a similarity score of 1, thus 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Black, Red,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 2 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTGHT_11 In the Box 2 shorts\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['Buy Wallmantra Extra Large Vinyl Stickers Sticker for Rs.2194 online. Wallmantra Extra Large Vinyl Stickers Sticker at best prices with FREE shipping & cash on delivery. Only Genuine Products. 30 Day Replacement Guarantee.']\n",
    "b = ['Buy Wallmantra Extra Large Vinyl Stickers Sticker for Rs.2194 online. Wallmantra Extra Large Vinyl Stickers Sticker at best prices with FREE shipping & cash on delivery. Only Genuine Products. 30 Day Replacement Guarantee.']\n",
    "\n",
    "similar(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.922509225092251"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar(df.loc[0]['description'],df.loc[3]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Key Features of Eternal Gandhi Super Series Crystal Paper Weights  with Silver Finish Crystal  paper weight Product Dimensions :   8cm x  8cm x 5cm A beautiful product Material: Crystal,Eternal Gandhi Super Series Crystal Paper Weights  with Silver Finish (Set Of 1, Clear) Price: Rs. 430 Your office desk will sparkle and shine when you accent tables with this elegant crystal paper weight. The multifaceted crystal features Gandhiji’s bust and his timeless message – “My life is my message – M.K. Gandhi”. A beautiful product to gift to your near and dear ones in family and Business.,Specifications of Eternal Gandhi Super Series Crystal Paper Weights  with Silver Finish (Set Of 1, Clear) General Model Name Gandhi Paper Weight Mark V Dimensions Weight 323 g In the Box Paper Weight Paper Weight Features Paper Weight Material Crystal Paper Weight Finish Silver Finish'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_description = df.loc[5]['description']\n",
    "product_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paper',\n",
       " 'crystal',\n",
       " 'weight',\n",
       " 'gandhi',\n",
       " 'finish',\n",
       " 'silver',\n",
       " 'eternal',\n",
       " 'super',\n",
       " 'series',\n",
       " 'weights',\n",
       " 'dimensions',\n",
       " '8cm',\n",
       " 'x',\n",
       " 'beautiful',\n",
       " 'set',\n",
       " '1',\n",
       " 'clear',\n",
       " 'message',\n",
       " '5cm',\n",
       " 'rs']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tags created by the product tagging algorithm\n",
    "tags = tokenize_string(product_description)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_string = ' '.join(map(str, tags))\n",
    "# joined_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paper', 'NN'),\n",
       " ('crystal', 'NN'),\n",
       " ('weight', 'VBD'),\n",
       " ('gandhi', 'JJ'),\n",
       " ('finish', 'JJ'),\n",
       " ('silver', 'NN'),\n",
       " ('eternal', 'JJ'),\n",
       " ('super', 'JJ'),\n",
       " ('series', 'NN'),\n",
       " ('weights', 'NNS'),\n",
       " ('dimensions', 'NNS'),\n",
       " ('8cm', 'CD'),\n",
       " ('x', 'JJ'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('set', 'VBN'),\n",
       " ('1', 'CD'),\n",
       " ('clear', 'JJ'),\n",
       " ('message', 'NN'),\n",
       " ('5cm', 'CD'),\n",
       " ('rs', 'NN')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagger = nltk.pos_tag(tags)\n",
    "pos_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('tagsets')\n",
    "nltk.help.upenn_tagset('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('JJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine words like weight - weights so we dont use the 'same' tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_tags = []\n",
    "for i in tags:\n",
    "    stemmed_tags.append(porter.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stemmed_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_tag(set_tags): \n",
    "    \"\"\"This function uses the NLTK lemmatizer function. Lemmatization, unlike Stemming, \n",
    "    reduces the inflected words properly ensuring that the root word belongs to the language\n",
    "    See: https://www.datacamp.com/community/tutorials/stemming-lemmatization-python\n",
    "\n",
    "    To reduce the amount of duplicates in a set of tags we will thus use lemmatization.\n",
    "    Words like 'weight' and 'weights' will be considered the same and be saved\n",
    "    as 'weight'. \n",
    "    \"\"\"\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lemm_set = []\n",
    "    for word in tokenize_string(set_tags):\n",
    "        tag = lemmatizer.lemmatize(word)\n",
    "        lemm_set.append(tag)\n",
    "    \n",
    "    lemm_set = list(set(lemm_set))\n",
    "    lemm_set = [x for x in lemm_set if not any(c.isdigit() for c in x)]\n",
    "    \n",
    "    return [i for i in lemm_set if len(i) > 1] # remove words with single character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genuine',\n",
       " 'pigmented',\n",
       " 'cash',\n",
       " 'extra',\n",
       " 'price',\n",
       " 'film',\n",
       " 'polyvinyl',\n",
       " 'free',\n",
       " 'imported',\n",
       " 'best',\n",
       " 'large',\n",
       " 'buy',\n",
       " 'online',\n",
       " 'delivery',\n",
       " 'product',\n",
       " 'shipping',\n",
       " 'uberlyfe',\n",
       " 'sticker']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = lemma_tag(df.loc[19900]['description'])\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the lemmatizer function we can track down the duplicates in a set of tags and delete them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar('weight','weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar('walking','walk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar('reading','read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar('hoping','hope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar('helping','help')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar('stressed','stress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diff_set = []\n",
    "for i in tags:\n",
    "    diff_set.append(difflib.get_close_matches(i, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diff_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_set[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_rate(description):\n",
    "    \"\"\"This function calculates the similarity score between words that are similar to eachother in a list of tags.\n",
    "    \n",
    "    :param description: A product description. \n",
    "    :type description: string\n",
    "    \"\"\"\n",
    "    \n",
    "    tagged_list = tokenize_string(description)\n",
    "    \n",
    "    diff_set = []\n",
    "    for i in tagged_list:\n",
    "        diff_set.append(difflib.get_close_matches(i, tagged_list))\n",
    "    \n",
    "    scores = []\n",
    "    for i in range(len(diff_set)):\n",
    "        if not len(diff_set[i]) <= 1:\n",
    "            firstW = diff_set[i][0]\n",
    "            secondW = diff_set[i][1]\n",
    "            similarityScore = similar(diff_set[i][0],diff_set[i][1])\n",
    "            scores.append([firstW, secondW, similarityScore])\n",
    "#             print(\"Score of similarity for {} and {} is: {}\".format(firstW, secondW, similarityScore))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_diff = similarity_rate(product_description)\n",
    "scores_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [sublist[-1] for sublist in scores_diff]:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python38064bit94409e1e4df94da1b5cc700cc0e6ab29"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
